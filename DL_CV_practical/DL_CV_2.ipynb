{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPccBuaLk1DgwTRidvl++2O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Somesh140/iNeauron_FSDS_Assignments/blob/main/DL_CV_practical/DL_CV_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import os\n",
        "import tarfile\n",
        "import urllib.request\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from flask import Flask, render_template, request"
      ],
      "metadata": {
        "id": "L2V-7pq64j4r"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download and extract CIFAR-100 dataset\n",
        "dataset_url = \"https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\"\n",
        "dataset_file = \"cifar-10-python.tar.gz\"\n",
        "dataset_folder = \"cifar-10-python\"\n",
        "if not os.path.exists(dataset_folder):\n",
        "    urllib.request.urlretrieve(dataset_url, dataset_file)\n",
        "    with tarfile.open(dataset_file, \"r:gz\") as tar:\n",
        "        tar.extractall()\n",
        "    os.remove(dataset_file)"
      ],
      "metadata": {
        "id": "tb2y9MsL4phm"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load CIFAR-100 dataset\n",
        "def load_dataset():\n",
        "    def unpickle(file):\n",
        "        import pickle\n",
        "        with open(file, 'rb') as fo:\n",
        "            dict = pickle.load(fo, encoding='bytes')\n",
        "        return dict\n",
        "\n",
        "    train_data = []\n",
        "    train_labels = []\n",
        "    test_data = []\n",
        "    test_labels = []\n",
        "\n",
        "    # Load training data\n",
        "    for i in range(1, 6):\n",
        "        file_path = os.path.join(dataset_folder, \"train_data_batch_{}\".format(i))\n",
        "        data = unpickle(file_path)\n",
        "        train_data.append(data[b'data'])\n",
        "        train_labels += data[b'fine_labels']\n",
        "\n",
        "    # Load test data\n",
        "    file_path = os.path.join(dataset_folder, \"test_data\")\n",
        "    data = unpickle(file_path)\n",
        "    test_data.append(data[b'data'])\n",
        "    test_labels += data[b'fine_labels']\n",
        "\n",
        "    # Convert data to numpy arrays\n",
        "    train_data = np.concatenate(train_data, axis=0)\n",
        "    test_data = np.concatenate(test_data, axis=0)\n",
        "    train_labels = np.array(train_labels)\n",
        "    test_labels = np.array(test_labels)\n",
        "\n",
        "    return train_data, train_labels, test_data, test_labels"
      ],
      "metadata": {
        "id": "Klm756Xh4usk"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Build and train your model here using TensorFlow or PyTorch\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar100\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load CIFAR-100 dataset\n",
        "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
        "\n",
        "# Preprocess and normalize the data\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "# Convert labels to categorical\n",
        "y_train = to_categorical(y_train, num_classes=100)\n",
        "y_test = to_categorical(y_test, num_classes=100)\n",
        "\n",
        "# Build the CNN model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(32, 32, 3)))\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(100, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, batch_size=128, epochs=20, validation_data=(x_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5o7yg4Bv5PIl",
        "outputId": "302882f7-ccdf-47c5-ff56-b69aba445091"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "169001437/169001437 [==============================] - 6s 0us/step\n",
            "Epoch 1/20\n",
            "391/391 [==============================] - 352s 895ms/step - loss: 4.0397 - accuracy: 0.0822 - val_loss: 3.4214 - val_accuracy: 0.1917\n",
            "Epoch 2/20\n",
            "391/391 [==============================] - 356s 911ms/step - loss: 3.3187 - accuracy: 0.2020 - val_loss: 2.8901 - val_accuracy: 0.2940\n",
            "Epoch 3/20\n",
            "391/391 [==============================] - 353s 903ms/step - loss: 2.9396 - accuracy: 0.2741 - val_loss: 2.6354 - val_accuracy: 0.3402\n",
            "Epoch 4/20\n",
            "391/391 [==============================] - 353s 903ms/step - loss: 2.7187 - accuracy: 0.3124 - val_loss: 2.5121 - val_accuracy: 0.3682\n",
            "Epoch 5/20\n",
            "391/391 [==============================] - 354s 905ms/step - loss: 2.5509 - accuracy: 0.3500 - val_loss: 2.3485 - val_accuracy: 0.4012\n",
            "Epoch 6/20\n",
            "391/391 [==============================] - 352s 900ms/step - loss: 2.4136 - accuracy: 0.3757 - val_loss: 2.2969 - val_accuracy: 0.4120\n",
            "Epoch 7/20\n",
            "391/391 [==============================] - 358s 916ms/step - loss: 2.3080 - accuracy: 0.3979 - val_loss: 2.2336 - val_accuracy: 0.4247\n",
            "Epoch 8/20\n",
            "391/391 [==============================] - 355s 908ms/step - loss: 2.2160 - accuracy: 0.4152 - val_loss: 2.1753 - val_accuracy: 0.4403\n",
            "Epoch 9/20\n",
            "391/391 [==============================] - 347s 889ms/step - loss: 2.1270 - accuracy: 0.4350 - val_loss: 2.1335 - val_accuracy: 0.4474\n",
            "Epoch 10/20\n",
            "391/391 [==============================] - 348s 891ms/step - loss: 2.0516 - accuracy: 0.4517 - val_loss: 2.1156 - val_accuracy: 0.4469\n",
            "Epoch 11/20\n",
            "391/391 [==============================] - 347s 888ms/step - loss: 1.9666 - accuracy: 0.4695 - val_loss: 2.0970 - val_accuracy: 0.4517\n",
            "Epoch 12/20\n",
            "391/391 [==============================] - 339s 867ms/step - loss: 1.9106 - accuracy: 0.4811 - val_loss: 2.0830 - val_accuracy: 0.4545\n",
            "Epoch 13/20\n",
            "391/391 [==============================] - 337s 861ms/step - loss: 1.8449 - accuracy: 0.4930 - val_loss: 2.0560 - val_accuracy: 0.4646\n",
            "Epoch 14/20\n",
            "391/391 [==============================] - 341s 871ms/step - loss: 1.7849 - accuracy: 0.5059 - val_loss: 2.0564 - val_accuracy: 0.4647\n",
            "Epoch 15/20\n",
            "391/391 [==============================] - 338s 863ms/step - loss: 1.7570 - accuracy: 0.5135 - val_loss: 2.0657 - val_accuracy: 0.4646\n",
            "Epoch 16/20\n",
            "391/391 [==============================] - 340s 869ms/step - loss: 1.6967 - accuracy: 0.5278 - val_loss: 2.0556 - val_accuracy: 0.4679\n",
            "Epoch 17/20\n",
            "391/391 [==============================] - 353s 903ms/step - loss: 1.6523 - accuracy: 0.5366 - val_loss: 2.0795 - val_accuracy: 0.4608\n",
            "Epoch 18/20\n",
            "391/391 [==============================] - 357s 912ms/step - loss: 1.5975 - accuracy: 0.5471 - val_loss: 2.0655 - val_accuracy: 0.4677\n",
            "Epoch 19/20\n",
            "391/391 [==============================] - 350s 895ms/step - loss: 1.5666 - accuracy: 0.5550 - val_loss: 2.0547 - val_accuracy: 0.4711\n",
            "Epoch 20/20\n",
            "391/391 [==============================] - 343s 878ms/step - loss: 1.5322 - accuracy: 0.5654 - val_loss: 2.0479 - val_accuracy: 0.4756\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd3b019f6d0>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "model.save('cifar100_model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        },
        "id": "kFVmFR5oKYLc",
        "outputId": "0b314107-ef8a-4e78-a722-82cc29002da4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-5895eb6505ca>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Save the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cifar100_model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eRu6D1mm4K0O"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Create Flask application\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Define route for home page\n",
        "@app.route('/')\n",
        "def home():\n",
        "    return render_template('index.html')\n",
        "\n",
        "# Define route for image classification\n",
        "@app.route('/classify', methods=['POST'])\n",
        "def classify():\n",
        "    # Get uploaded image from request\n",
        "    uploaded_image = request.files['image']\n",
        "    \n",
        "    # Save the uploaded image to a temporary file\n",
        "    temp_image_path = 'temp_image.jpg'\n",
        "    uploaded_image.save(temp_image_path)\n",
        "    \n",
        "    # Open and preprocess the image\n",
        "    image = Image.open(temp_image_path)\n",
        "    image = image.resize((32, 32))  # Resize the image to match CIFAR-100 size\n",
        "    image = np.array(image)\n",
        "    image = image.astype('float32') / 255.0\n",
        "    \n",
        "    # Perform image classification using your trained model\n",
        "    # Replace this with your own code for prediction\n",
        "    predicted_class = 0\n",
        "    prediction_score = 0.0\n",
        "    \n",
        "    return render_template('result.html', predicted_class=predicted_class, prediction_score=prediction_score)\n",
        "\n",
        "# Run the Flask application\n",
        "if __name__ == '__main__':\n",
        "    app.run(debug=True)\n"
      ]
    }
  ]
}